# ğŸ“Š EquIntel â€“ AI-Powered Equity Research Analyst (RAG + LLM)

**EquiIntel** is a local-first, AI-powered equity research platform that leverages cutting-edge Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) techniques to analyze financial documents, research reports, and market insights â€” all from your own database of PDFs.

Think of it as your very own BloombergGPT-lite that runs *entirely locally*.

---

## ğŸš€ Features

- âœ… **Upload & Ingest PDFs** (research reports, IMF docs, 10-Ks, earnings reports)
- ğŸ§  **Local LLM (Mistral 7B)** for secure & fast generation
- ğŸ” **Semantic Search with FAISS** â€” find relevant info across hundreds of documents
- ğŸ§¾ **Metadata Tagging** â€” categorize by sector, source, date, etc.
- ğŸ’¬ **RAG-based Q&A Interface** â€” ask financial questions and get contextual answers
- ğŸ“Š **Pluggable Analytics Layer** (coming soon!) â€” sentiment tracking, equity scores, view comparisons

---

## ğŸ—ï¸ Tech Stack

| Component        | Tool/Library                          |
|------------------|----------------------------------------|
| LLM              | `llama-cpp-python` (Mistral 7B GGUF)   |
| Embeddings       | `sentence-transformers`               |
| Vector Store     | `FAISS`                               |
| PDF Parsing      | `PyPDF2`, `LangChain PDF Loaders`     |
| RAG Framework    | `LangChain`                           |
| UI               | `Streamlit` (for later phases)        |
| Metadata Handling| Custom parser based on filename logic |

---

## ğŸ§± Project Structure

# ğŸ“Š EquIntel â€“ AI-Powered Equity Research Analyst

**EquIntel** is a local-first AI-powered equity research tool that leverages advanced LLMs and RAG techniques to analyze financial documents such as 10-Ks, earnings calls, and analyst reports.

Think of it as your private BloombergGPT â€” built for accuracy, privacy, and power.

---

## ğŸ”§ Architecture Overview

- ğŸ“ Parse and ingest financial PDFs (10-Ks, 10-Qs, earnings calls)
- âœ‚ï¸ Chunk text into semantically meaningful units
- ğŸ§  Embed chunks using sentence-transformers or OpenAI embeddings
- ğŸ“¦ Store vectors + metadata in **LanceDB**
- ğŸ” Perform vector search with contextual filtering (e.g., ticker, year, section)
- ğŸ¤– Use RAG to answer complex queries using a local or API-based LLM

---

## ğŸ—ƒï¸ LanceDB for Vector Storage

We use **[LanceDB](https://github.com/lancedb/lancedb)** as our vector database to store:
- Embeddings of parsed financial documents
- Structured metadata: ticker, doc type, section, date, etc.
- Enables efficient semantic + filtered retrieval

---

## ğŸ§± LanceDB Schema

```python
{
  "chunk_id": str,
  "text": str,
  "embedding": List[float],
  "ticker": str,
  "doc_type": str,
  "quarter": str,
  "year": int,
  "section": str,
  "source": str
}
ğŸ“¥ Getting Started
bash
Copy
Edit
git clone https://github.com/your-org/equintel.git
cd equintel
pip install -r requirements.txt
python pipeline/download_and_embed.py  # Build your dataset
ğŸ§  Example Queries
"Summarize Nvidiaâ€™s AI focus over the last 3 earnings calls."

"Compare capex growth of TSM and INTC over 2 quarters."

"List companies with declining gross margins in 2023."

ğŸ”’ Privacy & Local Execution
EquIntel is 100% local-first:

No cloud calls unless explicitly configured

Suitable for internal, proprietary, or institutional research use

ğŸ“œ License
MIT

yaml
Copy
Edit

---

Would you like me to write the full `lancedb` storage code next, including:
- Vector insertion
- Metadata tagging
- Query filter with `where` clauses?

Or update your repo with that automatically?
